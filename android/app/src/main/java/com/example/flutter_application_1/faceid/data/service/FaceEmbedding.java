package com.example.flutter_application_1.faceid.data.service;

import android.content.Context;
import android.graphics.Bitmap;
import android.graphics.Color;
import android.os.Handler;
import android.os.Looper;
import android.util.Log;
import android.widget.Toast;

import androidx.annotation.NonNull;


import org.tensorflow.lite.Interpreter;
import org.tensorflow.lite.gpu.GpuDelegate;
import org.tensorflow.lite.support.common.FileUtil;
import org.tensorflow.lite.support.common.TensorOperator;
import org.tensorflow.lite.support.image.ImageProcessor;
import org.tensorflow.lite.support.image.TensorImage;
import org.tensorflow.lite.support.image.ops.ResizeOp;
import org.tensorflow.lite.support.tensorbuffer.TensorBuffer;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.MappedByteBuffer;
import java.util.Arrays;
import java.util.Random;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.Executor;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;

/**
 * Utility class for generating face embeddings using FaceNet
 * Adapted from the OnDevice-Face-Recognition-Android project
 */
public class FaceEmbedding {
    private static final String TAG = "FaceEmbedding";
    private static final String MODEL_FILE = "facenet_512.tflite";
    
    // Input image size for FaceNet model
    private static final int IMG_SIZE = 160;
    
    // Output embedding size
    private static final int EMBEDDING_DIM = 512;
    
    private Interpreter interpreter;
    private ImageProcessor imageProcessor;
    private boolean useMockEmbedding = false;
    private final Random random = new Random();
    private final Executor executor = Executors.newSingleThreadExecutor();
    private final Handler mainHandler = new Handler(Looper.getMainLooper());
    private final Context context;
    
    private volatile boolean isInitialized = false;
    private final CountDownLatch initLatch = new CountDownLatch(1);
    
    public FaceEmbedding(Context context) {
        this.context = context.getApplicationContext();
        
        // Khởi tạo model bất đồng bộ
        executor.execute(() -> {
            try {
                // Log thông tin về assets để debug
                logAssetsContent(context);
                
                try {
                    Log.d(TAG, "Loading FaceNet model...");
                    
                    // Initialize TFLiteInterpreter
                    Interpreter.Options interpreterOptions = TFLiteGpuDelegateManager.getInstance().getInterpreterOptions();
                    
                    // Tải model từ assets
                    MappedByteBuffer modelBuffer = FileUtil.loadMappedFile(context, MODEL_FILE);
                    
                    // Tạo interpreter
                    interpreter = new Interpreter(modelBuffer, interpreterOptions);
                    
                    // Image processor cho tiền xử lý
                    imageProcessor = new ImageProcessor.Builder()
                            .add(new ResizeOp(IMG_SIZE, IMG_SIZE, ResizeOp.ResizeMethod.BILINEAR))
                            .add(new StandardizeOp())
                            .build();
                    
                    Log.d(TAG, "Loaded FaceNet model successfully");
                    
                    // Kiểm tra model
                    inspectModel();
                    
                    isInitialized = true;
                } catch (Exception e) {
                    Log.e(TAG, "Error initializing TensorFlow Lite model: " + e.getMessage(), e);
                    mainHandler.post(() -> 
                        Toast.makeText(context, "Error loading face embedding model: " + e.getMessage(), Toast.LENGTH_LONG).show()
                    );
                    useMockEmbedding = true;
                }
            } catch (Exception e) {
                Log.e(TAG, "Error checking model file: " + e.getMessage(), e);
                mainHandler.post(() -> 
                    Toast.makeText(context, "Error validating face embedding model: " + e.getMessage(), Toast.LENGTH_LONG).show()
                );
                useMockEmbedding = true;
            } finally {
                initLatch.countDown();
            }
        });
    }
    
    public boolean isInitialized() {
        return isInitialized && interpreter != null;
    }
    
    public void awaitInitialization(long timeoutMs) throws InterruptedException {
        initLatch.await(timeoutMs, TimeUnit.MILLISECONDS);
    }
    
    private void logAssetsContent(Context context) {
        try {
            String[] files = context.getAssets().list("");
            Log.d(TAG, "Assets directory content: " + Arrays.toString(files));
            
            // Kiểm tra chi tiết về các file model
            for (String file : files) {
                if (file.endsWith(".tflite")) {
                    try {
                        MappedByteBuffer buffer = FileUtil.loadMappedFile(context, file);
                        Log.d(TAG, "Model file: " + file + ", size: " + buffer.capacity() + " bytes");
                    } catch (Exception e) {
                        Log.e(TAG, "Error inspecting model file " + file + ": " + e.getMessage(), e);
                    }
                }
            }
        } catch (IOException e) {
            Log.e(TAG, "Error listing assets directory: " + e.getMessage(), e);
        }
    }
    
    /**
     * Get face embedding asynchronously
     * @param bitmap Face bitmap
     * @param callback Callback for result
     */
    public void getFaceEmbeddingAsync(Bitmap bitmap, EmbeddingCallback callback) {
        executor.execute(() -> {
            try {
                // Ensure model is initialized
                if (!isInitialized()) {
                    try {
                        Log.d(TAG, "Waiting for model initialization...");
                        awaitInitialization(5000);
                    } catch (InterruptedException e) {
                        Log.e(TAG, "Model initialization interrupted", e);
                    }
                }
                
                float[] embedding = getFaceEmbedding(bitmap);
                mainHandler.post(() -> callback.onEmbeddingGenerated(embedding));
            } catch (Exception e) {
                Log.e(TAG, "Error generating embedding", e);
                mainHandler.post(() -> callback.onEmbeddingGenerated(generateMockEmbedding()));
            }
        });
    }
    
    /**
     * Callback interface for embedding generation
     */
    public interface EmbeddingCallback {
        void onEmbeddingGenerated(float[] embedding);
    }
    
    /**
     * Get face embedding for the given bitmap
     * @param bitmap Face bitmap
     * @return Embedding as float array
     */
    public float[] getFaceEmbedding(Bitmap bitmap) {
        // Nếu đang sử dụng mock embedding hoặc interpreter không được khởi tạo, tạo một embedding ngẫu nhiên nhưng nhất quán
        if (useMockEmbedding || interpreter == null || imageProcessor == null) {
            Log.d(TAG, "Using mock face embedding");
            return generateMockEmbedding();
        }

        try {
            Log.d(TAG, "Start generating face embedding for image size: " + bitmap.getWidth() + "x" + bitmap.getHeight());

            // Đảm bảo bitmap có kích thước đúng
            Bitmap resizedBitmap = Bitmap.createScaledBitmap(bitmap, IMG_SIZE, IMG_SIZE, true);
            Log.d(TAG, "Resized bitmap to: " + resizedBitmap.getWidth() + "x" + resizedBitmap.getHeight());

            // Chuyển đổi bitmap thành float array
            float[][][][] inputArray = new float[1][IMG_SIZE][IMG_SIZE][3];

            // Lặp qua từng pixel và chuẩn hóa giá trị
            for (int y = 0; y < IMG_SIZE; y++) {
                for (int x = 0; x < IMG_SIZE; x++) {
                    int pixel = resizedBitmap.getPixel(x, y);

                    // Chuẩn hóa giá trị RGB về dải [-1, 1]
                    inputArray[0][y][x][0] = (Color.red(pixel) - 127.5f) / 128.0f;
                    inputArray[0][y][x][1] = (Color.green(pixel) - 127.5f) / 128.0f;
                    inputArray[0][y][x][2] = (Color.blue(pixel) - 127.5f) / 128.0f;
                }
            }

            // Chuẩn bị output buffer
            float[][] outputBuffer = new float[1][EMBEDDING_DIM];

            // Chạy inference
            try {
                interpreter.run(inputArray, outputBuffer);
                Log.d(TAG, "Inference succeeded");
            } catch (Exception e) {
                Log.e(TAG, "Error running inference: " + e.getMessage(), e);

                // Thử phương pháp khác
                try {
                    // Tạo ByteBuffer với kích thước phù hợp
                    ByteBuffer inputBuffer = ByteBuffer.allocateDirect(4 * IMG_SIZE * IMG_SIZE * 3);
                    inputBuffer.order(ByteOrder.nativeOrder());

                    // Điền dữ liệu vào buffer
                    for (int i = 0; i < IMG_SIZE; i++) {
                        for (int j = 0; j < IMG_SIZE; j++) {
                            int pixel = resizedBitmap.getPixel(j, i);

                            // Chuẩn hóa và thêm vào buffer
                            inputBuffer.putFloat((Color.red(pixel) - 127.5f) / 128.0f);
                            inputBuffer.putFloat((Color.green(pixel) - 127.5f) / 128.0f);
                            inputBuffer.putFloat((Color.blue(pixel) - 127.5f) / 128.0f);
                        }
                    }

                    // Đặt lại vị trí buffer về đầu
                    inputBuffer.flip();

                    Log.d(TAG, "Created new buffer with capacity: " + inputBuffer.capacity() + " bytes");

                    // Thử chạy lại inference
                    interpreter.run(inputBuffer, outputBuffer);
                    Log.d(TAG, "Inference succeeded with new buffer");
                } catch (Exception e2) {
                    Log.e(TAG, "Error running inference with new buffer: " + e2.getMessage(), e2);
                    return generateMockEmbedding();
                }
            }

            // Lấy embedding
            float[] embedding = outputBuffer[0];
            Log.d(TAG, "Generated embedding with length: " + embedding.length);

            // L2 normalize embedding
            return l2Normalize(embedding);
        } catch (Exception e) {
            Log.e(TAG, "Error generating face embedding: " + e.getMessage(), e);
            // Trả về mock embedding trong trường hợp lỗi
            return generateMockEmbedding();
        }
    }
    
    /**
     * Generate a mock embedding for testing
     */
    private float[] generateMockEmbedding() {
        float[] mockEmbedding = new float[EMBEDDING_DIM];
        
        // Use a fixed seed for consistent results
        random.setSeed(1234);
        
        // Generate random values
        for (int i = 0; i < EMBEDDING_DIM; i++) {
            mockEmbedding[i] = random.nextFloat() * 2 - 1; // Range: -1 to 1
        }
        
        // L2 normalize
        return l2Normalize(mockEmbedding);
    }
    
    /**
     * L2 normalize the embedding
     */
    private float[] l2Normalize(float[] embedding) {
        float squareSum = 0;
        for (float val : embedding) {
            squareSum += val * val;
        }
        
        float norm = (float) Math.sqrt(squareSum);
        if (norm > 0) {
            for (int i = 0; i < embedding.length; i++) {
                embedding[i] = embedding[i] / norm;
            }
        }
        
        return embedding;
    }
    
    /**
     * Release resources
     */
    public void close() {
        if (interpreter != null) {
            interpreter.close();
        }
    }

    /**
     * Standardize image for FaceNet model
     */
    private static class StandardizeOp implements TensorOperator {
        @Override
        public TensorBuffer apply(TensorBuffer input) {
            float[] pixels = input.getFloatArray();

            // Standardize to [-1, 1] with mean 0 and std 1
            float mean = 127.5f;
            float std = 128.0f;

            for (int i = 0; i < pixels.length; i++) {
                pixels[i] = (pixels[i] - mean) / std;
            }

            TensorBuffer output = TensorBuffer.createFixedSize(input.getShape(), input.getDataType());
            output.loadArray(pixels);

            return output;
        }
    }

    private void inspectModel() {
        if (interpreter != null) {
            try {
                int inputTensorCount = interpreter.getInputTensorCount();
                Log.d(TAG, "Input tensor count: " + inputTensorCount);

                for (int i = 0; i < inputTensorCount; i++) {
                    int[] shape = interpreter.getInputTensor(i).shape();
                    String shapeStr = Arrays.toString(shape);
                    Log.d(TAG, "Input tensor " + i + " shape: " + shapeStr);
                    Log.d(TAG, "Input tensor " + i + " dataType: " + interpreter.getInputTensor(i).dataType());
                }

                int outputTensorCount = interpreter.getOutputTensorCount();
                Log.d(TAG, "Output tensor count: " + outputTensorCount);

                for (int i = 0; i < outputTensorCount; i++) {
                    int[] shape = interpreter.getOutputTensor(i).shape();
                    String shapeStr = Arrays.toString(shape);
                    Log.d(TAG, "Output tensor " + i + " shape: " + shapeStr);
                    Log.d(TAG, "Output tensor " + i + " dataType: " + interpreter.getOutputTensor(i).dataType());
                }
            } catch (Exception e) {
                Log.e(TAG, "Error inspecting model: " + e.getMessage(), e);
            }
        }
    }
} 
